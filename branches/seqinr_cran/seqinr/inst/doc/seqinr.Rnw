\documentclass{svmult}
% Springer-Verlag style for multiauthors books
\usepackage{graphicx}
\usepackage{url}
\SweaveOpts{prefix.string=figs/seqinr}


\begin{document}

\newcommand{\seqinr}{\texttt{seqin\bf{R}}}
\newcommand{\Seqinr}{\texttt{Seqin\bf{R}}}
%
% R output options
%
<<options, echo=FALSE, fig=FALSE>>=
options(prompt=" ", continue=" ", width = 60)
CurFileName <- get("file", env = parent.frame(3))
@

% SeqinR adds
\mainmatter              % start of the contributions
%
\title{\Seqinr{}: a contributed package to the R project for statistical
computing devoted to biological sequences retrieval and analysis}
%
\titlerunning{\Seqinr{}}  % abbreviated title (for running head)
%                                     also used for the TOC unless
%                                     \toctitle is used
%
\author{Delphine Charif\inst{1}, Jean R. Lobry\inst{1} }
%
\authorrunning{D. Charif \& J.R. Lobry}   % abbreviated author list (for running head)
%
%%%% modified list of authors for the TOC (add the affiliations)
\tocauthor{Delphine Charif (Universit\'{e} Claude Bernard - Lyon I), Jean R. Lobry (Universit\'{e} Claude Bernard - Lyon I)}
%
\institute{Universit\'{e} Claude Bernard - Lyon I\\
Laboratoire de Biom\'{e}trie, Biologie \'{E}volutive\\
CNRS UMR 5558 - INRIA Helix project\\
43 Bd 11/11/1918\\F-69622 VILLEURBANNE CEDEX, FRANCE\\
\texttt{http://pbil.univ-lyon1.fr/members/lobry/}
}

\maketitle              % typeset the title of the contribution

\begin{abstract}
The \seqinr{} package for the R environment is a library of
utilities to retrieve and analyse biological sequences. It provides an
interface between i) the R language and environment for statistical
computing and graphics and ii) the ACNUC sequence retrieval system for
nucleotide and protein sequence databases such as GenBank, EMBL,
SWISS-PROT. ACNUC is very efficient in providing direct access to
subsequences of biological interest (e.g. protein coding regions, tRNA
or rRNA coding regions) present in GenBank and in EMBL. Thanks to a
simple query language, it is then easy under R to select sequences of
interest and then use all the power of the R environment to analyze
them. The ACNUC databases can be locally installed but they are more
conveniently accessed through a web server to take advantage of
centralized daily updates. The aim of this paper is to provide a
handout on basic sequence analyses under \seqinr{} with a special focus
on multivariate methods.
\end{abstract}

\section{Introduction}

\subsection{About R and CRAN}

R \cite{R, RfromR} is a \emph{libre} language and environment for statistical computing and graphics 
which provides a wide variety of statistical and graphical techniques: linear and 
nonlinear modelling, statistical tests, time series analysis, classification, clustering, etc. 
Please consult the R project homepage at \texttt{http://www.R-project.org/} for 
further information. 

<<nmirrors, echo = FALSE>>=
nmirrors <- function( url = paste(getOption("CRAN"), "mirrors.html", sep="/") )
{
  readLines(url) -> tmp
  dtab <- grep("<table", tmp)
  ftab <- grep("</table", tmp)
  if( length(dtab) != length(ftab) )
  {
    stop("Unbalanced table while reading file")
  }
  if( ! all(ftab - dtab > 0) )
  {
    stop("overlapping table marks")
  }
  nm <- 0
  for( i in 1:length(dtab) )
  {
    nm <- nm + length(grep("http:", tmp[dtab[i]:ftab[i]]))
  }
  nm <- nm / 2
  return( list( nm = nm, nc = length(dtab) ) )
}
@

 The Comprehensive R Archive Network, CRAN, is a network of servers 
 around the world that store identical, up-to-date, versions of code and documentation 
 for R.
At compilation time of this document, there were \Sexpr{nmirrors()$nm} mirrors available 
from \Sexpr{nmirrors()$nc} countries.
Please use the CRAN mirror nearest to you to minimize network load, they are
listed at \texttt{http://cran.r-project.org/mirrors.html}.

\subsection{About this document}

In the terminology of the R project \cite{R, RfromR}, this document is a package \emph{vignette}.
The examples given thereafter were run under \texttt{\Sexpr{R.version.string}}
on \Sexpr{date()} with Sweave \cite{Sweave}.
The last compiled version of this document is distributed along with the \seqinr{}
package in the \texttt{/doc} folder. Once \seqinr{} has been installed, the
full path to the package is given by the following R code :

<<whereisdoc>>=
.find.package("seqinr")
@

\subsection{About sequin and \seqinr{}}

Sequin is the well known sofware used to submit sequences to GenBank, \seqinr{}
has definitively no connection with sequin. \seqinr{} is just a shortcut, with
no google hit, for "Sequences in R".

However, as a mnemotechnic tip, you may think about the \seqinr{} package
as the {\bf{R}}eciprocal function of sequin: with sequin you can submit sequences
to Genbank, with \seqinr{} you can {\bf{R}}etrieve sequences from Genbank. This is
a very good summary of a major functionality of the \seqinr{} package: to
provide an efficient access to sequence databases under R.

\subsection{About getting started}

You need a computer connected to the Internet. First, install R on your computer.
There are distributions for Linux, Mac and Windows users
on the CRAN (\texttt{http://cran.r-project.org}). Then, install the \texttt{ade4}
and the \texttt{seqinr} packages. This can be done directly in an R console
with the commands \texttt{install.packages("ade4")} and 
\texttt{install.packages("seqinr")}. Last, load the \seqinr{} package
with:

<<seqinr>>=
library(seqinr)
@

The command \texttt{lseqinr()} lists all what is defined in the package \seqinr{}:

<<lseqinr>>=
lseqinr()[1:9]
@

We have printed here only the first 9 entries because they are too numerous.
To get help on a specific function, say \texttt{aaa()}, just prefix its name
with a question mark, as in \texttt{?aaa} and press enter.

%
% How to get sequences
%
\section{How to get sequence data}

\subsection{Importing sequences from text files}

\subsubsection{Raw sequence data from fasta files}

The fasta format is very simple and widely used for simple import of
biological sequences. It begins with a single-line description starting
with a character \texttt{>}, followed by lines of sequence data
of maximum 80 character each. Examples of files in fasta format
are distributed with the \seqinr{} package in the \texttt{sequences}
directory:

<<fastafiles>>=
list.files(path = system.file("sequences", package = "seqinr"), pattern = ".fasta")
@

The function \texttt{read.fasta()} imports sequences from fasta files
into your workspace, for example:

<<readfasta>>=
seqaa <- read.fasta(File = system.file("sequences/seqAA.fasta", package = "seqinr"), seqtype="AA")
seqaa
@

A more consequent example is given in the fasta file \texttt{ct.fasta} which
contains the complete genome of \textit{Chlamydia trachomatis} that was
used in \cite{oriloc}. You should be able to reproduce figure 1b from this
paper with the following code:

<<oriloc, fig=TRUE>>=
out <- oriloc(seq.fasta = system.file("sequences/ct.fasta", package ="seqinr"),
      g2.coord = system.file("sequences/ct.coord", package = "seqinr"),
     oldoriloc = TRUE)
plot(out$st, out$sk/1000, type="l", xlab = "Map position in Kb",
         ylab = "Cumulated composite skew in Kb", 
         main = "Chlamydia trachomatis complete genome", las = 1)
abline(h = 0, lty = 2)
text(400, -4, "Terminus")
text(850, 9, "Origin")
@

Note that the algorithm has been improved since then and that it's
more advisable to use the default option \texttt{oldoriloc = FALSE}
if you are interested in the prediction of origins and terminus of
replication from base composition biases (more on this at
\url{http://pbil.univ-lyon1.fr/software/oriloc.html}).

\subsubsection{Importing aligned sequences data}

Example avec Ka/Ks.

\subsection{Complex queries in ACNUC databases}

There is a utility in \seqinr{} called \texttt{get.db.growth()}
to get some basic statistics about the growth of DNA databases:

<<dbg, fig = TRUE>>=
dbg <- get.db.growth()
plot(x = dbg$date,
  y = log10(dbg$Nucl),
  las = 1,
  main = "The growth of DNA databases",
  xlab = "Year",
  ylab = "Log10 number of nucleotides")
@

As a rule of thumb, after compression one nucleotide needs one octet
of disk space storage (because you need also the annotations corresponding
to the sequences), so that most likely you won't have enough space on
your computer to work with a local copy of a complete DNA database.
The idea is to import under R only the subset of sequences you are
interested in. This is done in three steps:

\begin{enumerate}
\item Select the database you want to work with the \texttt{choosebank()} function.
This function initiates remote access to an acnuc database. Called without arguments,
\texttt{choosebank()} gives the list of available databases:

<<choixbanque1>>=
choosebank()
@

If we want to work with GenBank, for instance, we call \texttt{choosebank()}
with \texttt{"genbank"} as an argument and store the result in a variable
in the workspace:

<<choixbanque2>>=
mybank <- choosebank("genbank")
str(mybank)
@

The list returned by \texttt{choosebank()} here means that in the database
called \texttt{\Sexpr{mybank$bankname}} at the compilation time
of this document there were 
\texttt{\Sexpr{formatC(as.integer(mybank$totseqs), big.mark=",")}}
sequences from
\texttt{\Sexpr{formatC(as.integer(mybank$totspecs), big.mark=",")}}
species and a total of
\texttt{\Sexpr{formatC(as.integer(mybank$totkeys), big.mark=",")}}
keywords. For the following, the most important item is the first one
of the list, \texttt{mybank\$socket}, which contains all the required
details of the socket connection.

\item Then, you have to say what you want, that is to compose a query
to select the subset of sequences you are interested in. The way to do this is
documented under \texttt{?query}, we just give here a simple example. 
In the query below, we want to select all the coding sequences 
(\texttt{t=cds}) from cat (\texttt{sp=felis catus}) that are not 
(\texttt{et no}) partial sequences (\texttt{k=partial}). 
We want the result to be stored in an object called \texttt{list1}.
<<query1>>=
query(socket = mybank$socket, listname = "list1", 
query = "sp=felis catus et t=cds et no k=partial", invisible = TRUE)
@
Now, there is in the workspace an object called \texttt{list1}, which
does not contain the sequences themselves but the \emph{sequence names} that fit 
the query. They are stored in the \texttt{req} component of the object,
let's see the first ten of them:

<<getNames>>=
sapply(list1$req[1:10], getName)
@

The first sequence that fit our request is \texttt{\Sexpr{getName(list1$req[[1]])}},
the second one is \texttt{\Sexpr{getName(list1$req[[2]])}}, and so on. Note that
the sequence name may have an extension, this corresponds to \emph{subsequences},
a specificity of the ACNUC system that allows to handle easily a
subsequence with a biological meaning, typically a gene.

Note that the component \texttt{call} of \texttt{list1} keeps a 
trace of the way we have selected the sequences. At this stage you can quit your R 
session saving the workspace image. The next time an R session is opened with the 
workspace image restored, there will be an object called \texttt{list1}, and 
looking into its \texttt{call} component will tell you that it contains the names 
of complete coding sequences from \textit{Felis catus}.

In practice, queries for sequences are rarely done in one step and are more likely
to be the result of an iterative, progressively refining, process. An important point
is that a list of sequences can be re-used. For instance, we can re-use \texttt{list1}
get only the list of sequences that were published in 2004:

<<query2>>=
query(socket = mybank$socket, listname = "list2", query = "list1 et y=2004", invisible = TRUE)
length(list2$req)
@

Hence, there were \Sexpr{length(list2$req)} complete coding sequences in 2004 for
\textit{Felis catus} in GenBank.

% PROBLEME lenteur avec cette requête:
%<<query2>>=
%query(socket = mybank$socket, listname = "list2", query = "sp=felis catus", invisible = TRUE)
%query(socket = mybank$socket, listname = "list3", query = "list2 et t=cds", invisible = TRUE)
%query(socket = mybank$socket, listname = "list4", query = "list3 et no k=partial", invisible = TRUE)
%identical(list1$req, list4$req)
%@
\item The sequence itself is obtained with the function \texttt{getSequence()}.
For example, the first 50 nucleotides of the first sequence of our request are:

<<getSequence>>=
myseq <- getSequence(list1$req[[1]])
myseq[1:50]
@
They can also be coerced as string of character with the function \texttt{c2s()}:
<<SequenceAsString>>=
c2s(myseq[1:50])
@
Note that what is done by \texttt{getSequence()} is much more complex
than a substring extraction because subsequences of biological interest are
not necessarily contiguous or even on the same DNA strand. Consider for
instance the following coding sequence from sequence \texttt{AE003734}:

\scriptsize
\begin{verbatim}
AE003734.PE35        Location/Qualifiers    (length=1833 bp)
     CDS             join(complement(162997..163210),
                     complement(162780..162919),complement(161238..162090),
                     146568..146732,146806..147266)
                     /gene="mod(mdg4)"
                     /locus_tag="CG32491"
                     /note="CG32491 gene product from transcript CG32491-RT;
                     trans-splicing"
\end{verbatim}
\normalsize

To get the coding sequence manually you would have join 5 different pieces 
from \texttt{AE003734} and some of them are in the complementary strand. 
With \texttt{getSequence()} you don't have to think about this:

<<transplicing>>=
query(socket = mybank$socket, listname = "list3", query = "N=AE003734.PE35", invisible = TRUE)
getSequence(list3$req[[1]]) -> transspliced
getTrans(transspliced) -> tsaa
tsaa[1:50]
@
%
% QUESTION: gestion des codes genetiques variants avec seqAcnucWeb ???
%
\end{enumerate}


\section{How to deal with sequence}

\subsection{Sequence classes}


There are at present three classes of sequences, depending on the way they were obtained:

\begin{itemize}
      \item {\bfseries seqFasta} is the class for the sequences that were imported from a fasta file
      \item {\bfseries seqAcnucWeb} is the class for the sequences coming from an ACNUC database server
      \item {\bfseries seqFrag} is the class for the sequences that are fragments of other sequences
\end{itemize}

\subsection{Generic methods for sequences}

All sequence classes are sharing a common interface, so that there are very few method names we have to remember. 
In addition, all classes have their specific as.ClassName method that return an instance of the class,
and is.ClassName method to check whether an object belongs or not to the class. 
Available methods are: 
\\
\\
\begin{tabular}{|@{} c @{}|@{} c @{}|@{} c @{}|}
\hline
{\bfseries Methods} & {\bfseries Result} & {\bfseries Type of result} \\
\hline \hline
{\bfseries getFrag} & a sequence fragment & a sequence fragment \\
\hline
{\bfseries getSequence} & the sequence & vector of characters \\
\hline
{\bfseries getName} & the name of a sequence & string \\
\hline
{\bfseries getLength} & the length of a sequence & numeric vector \\
\hline
{\bfseries getTrans} & translation into amino-acids & vector of characters \\
\hline
{\bfseries getAnnot} & sequence annotations & vector of string \\
\hline
{\bfseries getLocation} & the Position of a Sequence on the Parent Sequence & list of numeric vector \\
\hline
\end{tabular}

\subsection{Internal representation of sequences}

The current mode of sequence storage is done with vectors of characters instead of strings.
This is very convenient for the user because all R tools to manipulate vectors are immediatly available. 
The price to pay is that this storage mode is extremly expensive in terms of memory.
They are two utilities called \texttt{s2c()} and \texttt{c2s()} that allows to convert strings into 
vector of characters, and \textit{vice versa}, respectively.

\subsubsection{Sequences as vectors of characters}

In the vectorial representation mode, all the very convenient R tools for indexing vectors
are at hand.
\begin{enumerate}
\item Vectors can be indexed by a vector of \emph{positive} integers saying which
elements are to be selected. As we have already seen, the first 50 elements of a sequence
are easily extracted thanks to the binary operator \texttt{from:to}, as in:

<<fromto>>=
1:50
myseq[1:50]
@

The \texttt{seq()} function allows to build more complexe integer vectors. For instance
in coding sequences it is very common to focus on third codon positions where
selection is weak. Let's extract bases from third codon positions:

<<seqtcp>>=
tcp <- seq(from = 3, to = length(myseq), by = 3)
tcp[1:10]
myseqtcp <- myseq[tcp]
myseqtcp[1:10]
@
 
 \item Vectors can also be indexed by a vector of \emph{negative} integers saying which
elements have to be removed. For instance, if we want to keep first and second codon positions,
the easiest way is to remove third codon positions:

<<seqfscp>>=
-tcp[1:10]
myseqfscp <- myseq[-tcp]
myseqfscp[1:10]
@

\item Vectors are also indexable by a vector of \emph{logicals} whose \texttt{TRUE}
values say which elements to keep. Here is a different way to extract all third coding positions
from our sequence. First, we define a vector of three logicals with only the last one true:

<<ind>>=
ind <- c(F, F, T)
ind
@

This vector seems too short for our purpose because our sequence is much more longer
with its \Sexpr{length(myseq)} bases. But under R vectors are automatically \emph{recycled}
when they are not long enough:

<<myseqtcp2>>=
(1:30)[ind]
myseqtcp2 <- myseq[ind]
@

The result should be the same as previously:

<<identical>>=
 identical(myseqtcp, myseqtcp2)
@

This recycling rule is extremely convenient in practice but may have surprising
effects if you assume (incorrectly) that there is a stringent dimension control for R vectors
as in linear algebra.

\end{enumerate}

Another advantage of working with vector of characters is that most R functions
are vectorized so that many things can be done without explicit looping. Let's
give some very simple examples:

<<vectorized1>>=
sum(myseq == "a")
@

<<vecto2, fig=TRUE>>=
basecount <- table(myseq)
myseqname <- getName(list1$req[[1]])
dotchart(basecount, xlim = c(0, max(basecount)), pch = 19,
  main = paste("Base count in",  myseqname))
@

<<vecto3, fig=TRUE>>=
dinuclcount <- count(myseq, 2)
dotchart(dinuclcount[order(dinuclcount)], xlim = c(0, max(dinuclcount)), pch = 19,
  main = paste("Dinucleotide count in",  myseqname))
@

<<vecto4, fig=TRUE>>=
codonusage <- uco(myseq)
dotchart.uco(codonusage, main = paste("Codon usage in",  myseqname))
@


\subsubsection{Sequences as strings}

If you are interested in (fuzzy) pattern matching, then it is advisable to work with
sequence as strings to take advantage of \emph{regular expression} implemented
in R. The function \texttt{words.pos()} returns the positions of all occurrences
of a given regular expression. Let's suppose we want to know where are the trinucleotides
"cgt" in a sequence, that is the fragment CpGpT in the direct strand:

<<cgt>>=
mystring <- c2s(myseq)
words.pos("cgt", mystring)
@

We can also look for the fragment CpGpTpY to illustrate fuzzy matching because
Y (IUPAC code for pyrimidine) stands C or T:

<<fuzzy>>=
words.pos("cgt[ct]", mystring)
@

To look for all CpC dinucleotides separated by 3 or 4 bases:
<<fuzzy2>>=
words.pos("cc.{3,4}cc", mystring)
@

Virtually any pattern is easily encoded with a regular expression. This is
especially useful at the protein level because many functions can be attributed 
to short linear motifs.

%
% Sequence analyses
%
\section{Manipulation of sequence data}
%
% Multivariate analyses
%
\section{Multivariate analyses}

\subsection{Correspondence analysis}

This is the most popular multivariate data analysis technique for amino-acid
and codon count tables. Its primary goal is to transform a table of counts
into a graphical display, in which each gene (or protein) and each codon (or amino-acid)
is depicted as a point. Correspondence analysis (CA) may be defined as a special 
case of principal components analysis (PCA) with a different underlying metrics.
The interest of the metrics in CA, that is the way we measure the distance between
two individuals, is illustrated bellow with a very simple example with only
three proteins having only three amino-acids, so that we can represent exactly
on a map the consequences of the metric choice.

<<df>>=
df <- data.frame(matrix(c(130, 60, 60, 70, 40, 35, 0, 0, 5), nrow=3))
names(df) <- c("Ala", "Val", "Cys")
df
@

Let's first use the regular Euclidian metrics,
\begin{equation}
d^2(i,i') = \sum_{i=1}^{I}(n_{ij} - n_{i'j})^2
\label{euclidian}
\end{equation}
to visualize this small data set:

<<euclidian, fig = TRUE>>=
pco <- dudi.pco(dist(df), scann = F, nf = 2)
myplot <- function( res, ... )
{
  plot(res$li[ , 1], res$li[ , 2], ...)
  text(x = res$li[ , 1], y = res$li[ , 2], labels = 1:3, pos = ifelse(res$li[ , 2] < 0, 1, 3))
  perm <- c(3, 1, 2)
  lines( c(res$li[ , 1], res$li[perm, 1]), c(res$li[ , 2], res$li[perm, 2]))
}
myplot(pco, main = "Euclidian distance", asp = 1, pch = 19, xlab = "", ylab = "")
@

From this point of view, the first individual is far away from the two others. But
thinking about it, this is a rather trivial effect of protein size:

<<protsize>>=
rowSums(df)
@

With \Sexpr{rowSums(df)[1]} amino-acids, the first protein is two times bigger 
than the others so that when computing the Euclidian distance (\ref{euclidian}) its $n_{ij}$ entries
are on average very big, sending it away from the others.
To get rid of this trivial effect, the first
obvious idea is to divide counts by protein lengths so as to work with 
\emph{protein profiles}. The corresponding distance is,

\begin{equation}
d^2(i,i') = \sum_{i=1}^{I}(\frac{n_{ij}}{n_{i\bullet}} - \frac{n_{i'j}}{n_{i'\bullet}})^2
\label{euclprof}
\end{equation}

where $n_{i\bullet}$ and $n_{i'\bullet}$ stands for the total number of amino-acids
in protein $i$ and $i'$, respectively.

<<profile, fig = TRUE>>=
df1 <- df/rowSums(df)
df1
dudi.pco(dist(df1), scann = F, nf = 2) -> pco1
myplot(pco1, main = "Euclidian distance on protein profiles", asp = 1, pch = 19, xlab = "", ylab = "",
  ylim = range(pco1$li[ , 2])*1.2)
@

The pattern is now completely different with the three protein equally spaced.
This is normal because in terms of relative amino-acid composition they are
all differing two-by-two by $5\%$ at the level of two amino-acids only. We
have clearly removed the trivial protein size effect, but this is still not completely
satisfactory. The proteins are differing by $5\%$ for all amino-acids but the situation 
is somewhat different for \texttt{Cys} because this amino-acid is very rare.
A difference of $5\%$ for a rare amino-acid has not the same significance than
a difference of $5\%$ for a common amino-acid such as \texttt{Ala} in our
example. To cope with this, CA make use of a variance-standardizing
technique to compensate for the larger variance in high frequencies and the 
smaller variance in low frequencies. This is achieved with the use of the 
\emph{chi-square distance} ($\chi^2$) which differs from the previous Euclidean distance 
on profiles (\ref{euclprof}) in that each square is weighted by the inverse of 
the frequency corresponding to each term,

\begin{equation}
d^2(i,i') = \sum_{i=1}^{I}\frac{1}{n_{{\bullet}j}}(\frac{n_{ij}}{n_{i\bullet}} - \frac{n_{i'j}}{n_{i'\bullet}})^2
\label{chi}
\end{equation}

where $n_{{\bullet}j}$ is the total number of amino-acid of kind $j$. With this point
of view, the map is now like this:

<<afc, fig = TRUE>>=
coa <- dudi.coa(df, scann = FALSE, nf = 2)
myplot(coa, main = expression(paste(chi^2,"distance")), 
  asp = 1, pch = 19, xlab = "", ylab = "")
@

The pattern is completely different with now protein number 3 which is far away from
the others because it is enriched in the rare amino-acid \texttt{Cys} as compared to
others.

%warning importance of metric choice (COA on RSCU)
%advantages of COA
% principe d'eqivalence distri
% biplot

<<scatter, fig = TRUE>>=
scatter(coa, clab.col = 0.75, clab.row = 0.6)
@
%
% ---- Bibliography ----
%
\begin{thebibliography}{15}
%

\bibitem{Sweave}
Leisch, F.:
Sweave: Dynamic generation of statistical reports using literate data analysis.
Compstat 2002 --- Proceedings in Computational Statistics (2002) 575--580
ISBN 3-7908-1517-9.

\bibitem{oriloc}
Frank, A.C., Lobry, J.R.:
Oriloc: prediction of replication boundaries in unannotated bacterial chromosomes.
Bioinformatics {\bf 16} (2000) 560--561

\bibitem{R}
Ihaka, R., Gentleman, R.:
R: A Language for Data Analysis and Graphics.
J. Comp. Graph. Stat. {\bf 3} (1996) 299--314

\bibitem{RfromR}
R Development Core Team:
R: A language and environment for statistical computing
(2004) ISBN 3-900051-00-3, http://www.R-project.org
   



\end{thebibliography}

\end{document}
